{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import operator\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "from classifier import *\n",
    "from heapq import nlargest\n",
    "from issues import get_num_code_lines\n",
    "from nltk.stem import PorterStemmer\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, r2_score\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: concat all these into one file\n",
    "with open('../data/eclipse/eclpise_issues1.json') as json_data:\n",
    "    issues1 = json.load(json_data)\n",
    "with open('../data/eclipse/eclpise_issues2.json') as json_data:\n",
    "    issues2 = json.load(json_data)\n",
    "with open('../data/eclipse/eclpise_issues3.json') as json_data:\n",
    "    issues3 = json.load(json_data)\n",
    "with open('../data/eclipse/eclpise_issues4.json') as json_data:\n",
    "    issues4 = json.load(json_data)\n",
    "with open('../data/eclipse/eclpise_issues5.json') as json_data:\n",
    "    issues5 = json.load(json_data)\n",
    "with open('../data/eclipse/eclpise_issues6.json') as json_data:\n",
    "    issues6 = json.load(json_data)\n",
    "with open('../data/eclipse/eclpise_issues7.json') as json_data:\n",
    "    issues7 = json.load(json_data)\n",
    "with open('../data/eclipse/eclpise_issues8.json') as json_data:\n",
    "    issues8 = json.load(json_data)\n",
    "with open('../data/eclipse/eclpise_issues9.json') as json_data:\n",
    "    issues9 = json.load(json_data)\n",
    "with open('../data/eclipse/eclpise_issues10.json') as json_data:\n",
    "    issues10 = json.load(json_data)\n",
    "with open('../data/eclipse/eclpise_issues11.json') as json_data:\n",
    "    issues11 = json.load(json_data)\n",
    "with open('../data/eclipse/eclpise_issues12.json') as json_data:\n",
    "    issues12 = json.load(json_data)\n",
    "with open('../data/eclipse/eclpise_issues13.json') as json_data:\n",
    "    issues13 = json.load(json_data)\n",
    "issues = issues1 + issues2 + issues3 + issues4 + issues5 + issues6 + issues7 + issues8 + issues9 + issues10 + issues11 + issues12 + issues13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of issues: 272263\n",
      "Number of labeled issues: 140748\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of issues: \" + str(len(issues)))\n",
    "labeled_issues = [issue for issue in issues if issue['completed_by']]\n",
    "print(\"Number of labeled issues: \" + str(len(labeled_issues)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>closed_date</th>\n",
       "      <th>completed_by</th>\n",
       "      <th>component</th>\n",
       "      <th>created_date</th>\n",
       "      <th>product</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>Create two java projects: aaa and bbbUnder bbb...</td>\n",
       "      <td>2001-10-11</td>\n",
       "      <td>Claude_Knaus</td>\n",
       "      <td>UI\\n\\n  (show other bugs)\\n</td>\n",
       "      <td>2001-10-10</td>\n",
       "      <td>JDT\\n\\n</td>\n",
       "      <td>Move problem when folder has space in the name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>EG (27.09.2001 14:03:03)1) change the compiler...</td>\n",
       "      <td>2001-10-11</td>\n",
       "      <td>Claude_Knaus</td>\n",
       "      <td>UI\\n\\n  (show other bugs)\\n</td>\n",
       "      <td>2001-10-10</td>\n",
       "      <td>JDT\\n\\n</td>\n",
       "      <td>Compiler option settings not properly persiste...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   body closed_date  \\\n",
       "1310  Create two java projects: aaa and bbbUnder bbb...  2001-10-11   \n",
       "1223  EG (27.09.2001 14:03:03)1) change the compiler...  2001-10-11   \n",
       "\n",
       "      completed_by                    component created_date  product  \\\n",
       "1310  Claude_Knaus  UI\\n\\n  (show other bugs)\\n   2001-10-10  JDT\\n\\n   \n",
       "1223  Claude_Knaus  UI\\n\\n  (show other bugs)\\n   2001-10-10  JDT\\n\\n   \n",
       "\n",
       "                                                  title  \n",
       "1310  Move problem when folder has space in the name...  \n",
       "1223  Compiler option settings not properly persiste...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a data frame from the list of issues\n",
    "df_list = []\n",
    "for issue in labeled_issues:\n",
    "        df_dict = {}\n",
    "        df_dict['title'] = issue['short_desc'].replace(\"\\n\", \"\").replace(\"\\t\", \"\")\n",
    "        df_dict['body'] = issue['long_desc'].replace(\"\\n\", \"\").replace(\"\\t\", \"\")\n",
    "        df_dict['closed_date'] = pd.to_datetime(issue['completed_at'][:10])\n",
    "        df_dict['created_date'] = pd.to_datetime(issue['created_at'][:10])\n",
    "        df_dict['completed_by'] = issue['completed_by']\n",
    "        df_dict['product'] = issue['product']\n",
    "        df_dict['component'] = issue['component']\n",
    "        df_list.append(df_dict)\n",
    "df = pd.DataFrame(df_list).sort_values('closed_date')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>closed_date</th>\n",
       "      <th>completed_by</th>\n",
       "      <th>created_date</th>\n",
       "      <th>title</th>\n",
       "      <th>component_AI\n",
       "\n",
       "  (show other bugs)</th>\n",
       "      <th>component_AJBrowser\n",
       "\n",
       "  (show other bugs)</th>\n",
       "      <th>component_AJDoc\n",
       "\n",
       "  (show other bugs)</th>\n",
       "      <th>component_ALF\n",
       "\n",
       "  (show other bugs)</th>\n",
       "      <th>component_AM3\n",
       "\n",
       "  (show other bugs)</th>\n",
       "      <th>...</th>\n",
       "      <th>product_WTP Releng</th>\n",
       "      <th>product_WTP ServerTools</th>\n",
       "      <th>product_WTP Source Editing</th>\n",
       "      <th>product_WTP Webservices</th>\n",
       "      <th>product_WTP Website</th>\n",
       "      <th>product_Web Tools</th>\n",
       "      <th>product_Woolsey</th>\n",
       "      <th>product_XWT</th>\n",
       "      <th>product_e4</th>\n",
       "      <th>product_z_Archived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>Create two java projects: aaa and bbbUnder bbb...</td>\n",
       "      <td>2001-10-11</td>\n",
       "      <td>Claude_Knaus</td>\n",
       "      <td>2001-10-10</td>\n",
       "      <td>Move problem when folder has space in the name...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>EG (27.09.2001 14:03:03)1) change the compiler...</td>\n",
       "      <td>2001-10-11</td>\n",
       "      <td>Claude_Knaus</td>\n",
       "      <td>2001-10-10</td>\n",
       "      <td>Compiler option settings not properly persiste...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 564 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   body closed_date  \\\n",
       "1310  Create two java projects: aaa and bbbUnder bbb...  2001-10-11   \n",
       "1223  EG (27.09.2001 14:03:03)1) change the compiler...  2001-10-11   \n",
       "\n",
       "      completed_by created_date  \\\n",
       "1310  Claude_Knaus   2001-10-10   \n",
       "1223  Claude_Knaus   2001-10-10   \n",
       "\n",
       "                                                  title  \\\n",
       "1310  Move problem when folder has space in the name...   \n",
       "1223  Compiler option settings not properly persiste...   \n",
       "\n",
       "      component_AI\\n\\n  (show other bugs)\\n  \\\n",
       "1310                                      0   \n",
       "1223                                      0   \n",
       "\n",
       "      component_AJBrowser\\n\\n  (show other bugs)\\n  \\\n",
       "1310                                             0   \n",
       "1223                                             0   \n",
       "\n",
       "      component_AJDoc\\n\\n  (show other bugs)\\n  \\\n",
       "1310                                         0   \n",
       "1223                                         0   \n",
       "\n",
       "      component_ALF\\n\\n  (show other bugs)\\n  \\\n",
       "1310                                       0   \n",
       "1223                                       0   \n",
       "\n",
       "      component_AM3\\n\\n  (show other bugs)\\n           ...            \\\n",
       "1310                                       0           ...             \n",
       "1223                                       0           ...             \n",
       "\n",
       "      product_WTP Releng\\n\\n  product_WTP ServerTools\\n\\n  \\\n",
       "1310                       0                            0   \n",
       "1223                       0                            0   \n",
       "\n",
       "      product_WTP Source Editing\\n\\n  product_WTP Webservices\\n\\n  \\\n",
       "1310                               0                            0   \n",
       "1223                               0                            0   \n",
       "\n",
       "      product_WTP Website\\n\\n  product_Web Tools\\n\\n  product_Woolsey\\n\\n  \\\n",
       "1310                        0                      0                    0   \n",
       "1223                        0                      0                    0   \n",
       "\n",
       "      product_XWT\\n\\n  product_e4\\n\\n  product_z_Archived\\n\\n  \n",
       "1310                0               0                       0  \n",
       "1223                0               0                       0  \n",
       "\n",
       "[2 rows x 564 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encode the component and team columns\n",
    "df = pd.get_dummies(df, columns=[\"component\", \"product\"], prefix=[\"component\", \"product\"])\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129554\n"
     ]
    }
   ],
   "source": [
    "size = 120000\n",
    "#get list of devs who solve an issue in last three months (from end of train set)\n",
    "active_devs = set()\n",
    "dev_counts = {}\n",
    "filter_date = df.iloc[size]['closed_date'] - pd.to_timedelta(90, unit='d')\n",
    "for _, row in df.iterrows():\n",
    "    if (row['closed_date'] > filter_date):\n",
    "        dev_counts[row['completed_by']] = dev_counts.get(row['completed_by'], 0) + 1\n",
    "#print(dev_counts)\n",
    "for dev in dev_counts:\n",
    "    if dev_counts[dev] >= 3:\n",
    "        active_devs.add(dev)\n",
    "#print(active_devs)\n",
    "# remove all issues not solved by an active dev\n",
    "df = df[df['completed_by'].isin(active_devs)].reset_index(drop=True)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    # remove punctuation and non-alpha numeric characters\n",
    "    split1 = ' '.join([word for word in re.split('\\W+', text) if word.isalpha()])\n",
    "    # split camel case words apart (necessary for embedded code) and apply stemmer to all words\n",
    "    split2 = ' '.join([stemmer.stem(word) for word in re.sub('(?!^)([A-Z][a-z]+)', r' \\1', split1).split()])\n",
    "    return split2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(129554, 88586)\n",
      "(129554, 12732)\n"
     ]
    }
   ],
   "source": [
    "# use tf-idf w/ stemming, stop-word removal, and non-alphabetic word removal to generate features\n",
    "df['body'] = df['body'].apply(preprocess)\n",
    "vectorizer_body = TfidfVectorizer(stop_words=ENGLISH_STOP_WORDS)\n",
    "vectorizer_body.fit(df['body'])\n",
    "vector_body = vectorizer_body.transform(df['body'])\n",
    "# summarize encoded vector\n",
    "print(vector_body.shape)\n",
    "df['title'] = df['title'].apply(preprocess)\n",
    "vectorizer_title = TfidfVectorizer(stop_words=ENGLISH_STOP_WORDS)\n",
    "vectorizer_title.fit(df['title'])\n",
    "vector_title = vectorizer_title.transform(df['title'])\n",
    "# summarize encoded vector\n",
    "print(vector_title.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "(129554, 101318)\n",
      "(129554, 101318)\n",
      "(129554, 101877)\n"
     ]
    }
   ],
   "source": [
    "print(type(vector_title))\n",
    "print(type(vector_body))\n",
    "sparse_data = hstack((vector_title, vector_body))\n",
    "print(sparse_data.shape)\n",
    "#TODO: these should be numerical features before combining\n",
    "df['completed_by'] = df['completed_by'].astype('category')\n",
    "df['completed_by_encode'] = df['completed_by'].cat.codes\n",
    "#df['completed_by'] = pd.factorize(df['completed_by'])\n",
    "#sparse_data = hstack((sparse_data,np.array(df['completed_by_encode'])[:,None]))\n",
    "print(sparse_data.shape)\n",
    "#TODO: add component and team\n",
    "filter_cols = [col for col in df if col.startswith('product') or col.startswith('component')]\n",
    "sparse_data = hstack((sparse_data,np.array(df[filter_cols]))).tocsr()\n",
    "print(sparse_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntrain_df = df[:size]\\ntest_df = df[size:]\\nX_train = train_df.drop(['body', 'closed_date', 'completed_by', 'created_date', 'title', 'completed_by_encode'], axis=1)\\ny_train = train_df['completed_by']\\nX_test = test_df.drop(['body', 'closed_date', 'completed_by', 'created_date', 'title', 'completed_by_encode'], axis=1)\\ny_test = test_df['completed_by']\\n\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = sparse_data[:size]\n",
    "X_test = sparse_data[size:]\n",
    "y_train = df['completed_by'][:size]\n",
    "y_test = df['completed_by'][size:]\n",
    "\n",
    "'''\n",
    "train_df = df[:size]\n",
    "test_df = df[size:]\n",
    "X_train = train_df.drop(['body', 'closed_date', 'completed_by', 'created_date', 'title', 'completed_by_encode'], axis=1)\n",
    "y_train = train_df['completed_by']\n",
    "X_test = test_df.drop(['body', 'closed_date', 'completed_by', 'created_date', 'title', 'completed_by_encode'], axis=1)\n",
    "y_test = test_df['completed_by']\n",
    "'''\n",
    "#print(len(X_train))\n",
    "#print(len(X_test))\n",
    "#X_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_correct_top_k(pred_prob, k, actual, labels):\n",
    "    indices = [i for i in range(len(pred_prob))]\n",
    "    top_indices = nlargest(k, indices, key=lambda i: pred_prob[i])\n",
    "    top_choices = set([labels[i] for i in top_indices])\n",
    "    return actual in top_choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 Accuracy: 0.31316725978647686\n",
      "Top 2 Accuracy: 0.4485032447142558\n",
      "Top 3 Accuracy: 0.5378898890517061\n",
      "Top 4 Accuracy: 0.6009001465354825\n",
      "Top 5 Accuracy: 0.6508268787942223\n"
     ]
    }
   ],
   "source": [
    "classifier = MLPClassifier(hidden_layer_sizes=(25,25))\n",
    "classifier.fit(X_train,y_train)\n",
    "classes = classifier.classes_\n",
    "print(\"Top 1 Accuracy: \" + str(classifier.score(X_test, y_test)))\n",
    "pred_probs = classifier.predict_proba(X_test)\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 2, y_test[size + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 2 Accuracy: \" + str((correct/len(y_test))))\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 3, y_test[size + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 3 Accuracy: \" + str((correct/len(y_test))))\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 4, y_test[size + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 4 Accuracy: \" + str((correct/len(y_test))))\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 5, y_test[size + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 5 Accuracy: \" + str((correct/len(y_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclassifier = GaussianNB()\\nclassifier.fit(X_train,y_train)\\nclasses = classifier.classes_\\nprint(\"Top 1 Accuracy: \" + str(classifier.score(X_test, y_test)))\\npred_probs = classifier.predict_proba(X_test)\\ncorrect = 0\\nfor idx, pred in enumerate(pred_probs):\\n    if is_correct_top_k(pred, 2, y_test[size + idx], classes):\\n        correct += 1\\nprint (\"Top 2 Accuracy: \" + str((correct/len(y_test))))\\ncorrect = 0\\nfor idx, pred in enumerate(pred_probs):\\n    if is_correct_top_k(pred, 3, y_test[size + idx], classes):\\n        correct += 1\\nprint (\"Top 3 Accuracy: \" + str((correct/len(y_test))))\\ncorrect = 0\\nfor idx, pred in enumerate(pred_probs):\\n    if is_correct_top_k(pred, 4, y_test[size + idx], classes):\\n        correct += 1\\nprint (\"Top 4 Accuracy: \" + str((correct/len(y_test))))\\ncorrect = 0\\nfor idx, pred in enumerate(pred_probs):\\n    if is_correct_top_k(pred, 5, y_test[size + idx], classes):\\n        correct += 1\\nprint (\"Top 5 Accuracy: \" + str((correct/len(y_test))))\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train,y_train)\n",
    "classes = classifier.classes_\n",
    "print(\"Top 1 Accuracy: \" + str(classifier.score(X_test, y_test)))\n",
    "pred_probs = classifier.predict_proba(X_test)\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 2, y_test[size + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 2 Accuracy: \" + str((correct/len(y_test))))\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 3, y_test[size + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 3 Accuracy: \" + str((correct/len(y_test))))\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 4, y_test[size + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 4 Accuracy: \" + str((correct/len(y_test))))\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 5, y_test[size + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 5 Accuracy: \" + str((correct/len(y_test))))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclassifier = BernoulliNB()\\nclassifier.fit(X_train,y_train)\\nclasses = classifier.classes_\\nprint(\"Top 1 Accuracy: \" + str(classifier.score(X_test, y_test)))\\npred_probs = classifier.predict_proba(X_test)\\ncorrect = 0\\nfor idx, pred in enumerate(pred_probs):\\n    if is_correct_top_k(pred, 2, y_test[size + idx], classes):\\n        correct += 1\\nprint (\"Top 2 Accuracy: \" + str((correct/len(y_test))))\\ncorrect = 0\\nfor idx, pred in enumerate(pred_probs):\\n    if is_correct_top_k(pred, 3, y_test[size + idx], classes):\\n        correct += 1\\nprint (\"Top 3 Accuracy: \" + str((correct/len(y_test))))\\ncorrect = 0\\nfor idx, pred in enumerate(pred_probs):\\n    if is_correct_top_k(pred, 4, y_test[size + idx], classes):\\n        correct += 1\\nprint (\"Top 4 Accuracy: \" + str((correct/len(y_test))))\\ncorrect = 0\\nfor idx, pred in enumerate(pred_probs):\\n    if is_correct_top_k(pred, 5, y_test[size + idx], classes):\\n        correct += 1\\nprint (\"Top 5 Accuracy: \" + str((correct/len(y_test))))\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "classifier = BernoulliNB()\n",
    "classifier.fit(X_train,y_train)\n",
    "classes = classifier.classes_\n",
    "print(\"Top 1 Accuracy: \" + str(classifier.score(X_test, y_test)))\n",
    "pred_probs = classifier.predict_proba(X_test)\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 2, y_test[size + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 2 Accuracy: \" + str((correct/len(y_test))))\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 3, y_test[size + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 3 Accuracy: \" + str((correct/len(y_test))))\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 4, y_test[size + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 4 Accuracy: \" + str((correct/len(y_test))))\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 5, y_test[size + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 5 Accuracy: \" + str((correct/len(y_test))))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "classifier.fit(X_train, y_train)\n",
    "classes = classifier.classes_\n",
    "print(\"Top 1 Accuracy: \" + str(classifier.score(X_test, y_test)))\n",
    "pred_probs = classifier.predict_proba(X_test)\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 2, y_test[size + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 2 Accuracy: \" + str((correct/len(y_test))))\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 3, y_test[size + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 3 Accuracy: \" + str((correct/len(y_test))))\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 4, y_test[size + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 4 Accuracy: \" + str((correct/len(y_test))))\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 5, y_test[size + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 5 Accuracy: \" + str((correct/len(y_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "classifier = RandomForestClassifier(n_estimators=1000)\n",
    "classifier.fit(X_train, y_train)\n",
    "classes = classifier.classes_\n",
    "print(\"Top 1 Accuracy: \" + str(classifier.score(X_test, y_test)))\n",
    "pred_probs = classifier.predict_proba(X_test)\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 2, y_test[size + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 2 Accuracy: \" + str((correct/len(y_test))))\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 3, y_test[size + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 3 Accuracy: \" + str((correct/len(y_test))))\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 4, y_test[size + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 4 Accuracy: \" + str((correct/len(y_test))))\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 5, y_test[size + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 5 Accuracy: \" + str((correct/len(y_test))))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: try SVC (might need to do something else)\n",
    "'''\n",
    "classifier = SVC(probability=True)\n",
    "classifier.fit(X_train, y_train)\n",
    "classes = classifier.classes_\n",
    "print(\"Top 1 Accuracy: \" + str(classifier.score(X_test, y_test)))\n",
    "pred_probs = classifier.predict_proba(X_test)\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 2, y_test[size + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 2 Accuracy: \" + str((correct/len(y_test))))\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 3, y_test[size + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 3 Accuracy: \" + str((correct/len(y_test))))\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 4, y_test[size + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 4 Accuracy: \" + str((correct/len(y_test))))\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 5, y_test[size + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 5 Accuracy: \" + str((correct/len(y_test))))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = MLPClassifier(hidden_layer_sizes=(25,25))\n",
    "classifier.fit(X_train,y_train)\n",
    "preds = classifier.predict(X_test)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = test_df['completed_by']\n",
    "pd.value_counts(actual).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(df['completed_by']).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(preds).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_counts = pd.value_counts(df['completed_by'])\n",
    "# list of devs sorted in order of highest contribution\n",
    "sorted_dev_list = overall_counts.index.values\n",
    "pred_counts = pd.value_counts(preds)\n",
    "actual_counts = pd.value_counts(actual)\n",
    "\n",
    "percent_diff = {}\n",
    "vals = []\n",
    "counts = []\n",
    "missing = set()\n",
    "for dev in sorted_dev_list:\n",
    "    if dev in pred_counts:\n",
    "        val = 100 * (pred_counts[dev] - actual_counts[dev]) / (actual_counts[dev])\n",
    "        percent_diff[dev] = val\n",
    "        counts.append(overall_counts[dev])\n",
    "        vals.append(val)\n",
    "    else:\n",
    "        missing.add(dev)\n",
    "print(\"devs not included in predictions: \")\n",
    "print(list(missing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(percent_diff.keys(), percent_diff.values())\n",
    "plt.title(\"Percent Difference Prediction Rate vs. Actual Rate\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the outlier\n",
    "del vals[2]\n",
    "del counts[2]\n",
    "# create best fit line\n",
    "z = np.polyfit(x=counts, y=vals, deg=1)\n",
    "p = np.poly1d(z)\n",
    "trend_line = p(counts)\n",
    "# test best fit\n",
    "yhat = trend_line    \n",
    "ybar = np.sum(vals)/len(vals)\n",
    "ssreg = np.sum((yhat-ybar)**2) \n",
    "sstot = np.sum((vals - ybar)**2)\n",
    "print(\"R^2: \" + str(ssreg / sstot))\n",
    "# create plots\n",
    "plt.scatter(counts, vals)\n",
    "plt.title(\"Percent Difference Between Prediction Rate and Actual Rate vs. Issue Count\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel(\"Number of Issues Solved\")\n",
    "plt.ylabel(\"% diff. pred rate and actual rate\")\n",
    "plt.plot(counts, trend_line)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: look at assigning open issues and seeing what overspecialization problem would look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.tail(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
