{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from issues import get_num_code_lines\n",
    "from classifier import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/flutter/flutter_issues_labeled_2.json') as json_data:\n",
    "    data = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num positive events: 819\n",
      "num total events: 2990\n"
     ]
    }
   ],
   "source": [
    "num_positive_labels = 0\n",
    "total_num_labels = 0\n",
    "for issue in data:\n",
    "    for assignee in issue['training_labels']:\n",
    "        if issue['training_labels'][assignee] == 1:\n",
    "            num_positive_labels += 1\n",
    "        total_num_labels += 1\n",
    "print(\"num positive events: \" + str(num_positive_labels))\n",
    "print(\"num total events: \" + str(total_num_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now filter out any issues that never end up getting a commit/PR before they are closed. Idea being that these are not 'real' issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num positive events: 819\n",
      "num total events: 937\n"
     ]
    }
   ],
   "source": [
    "num_positive_labels = 0\n",
    "total_num_labels = 0\n",
    "for issue in data:\n",
    "    for assignee in issue['training_labels']:\n",
    "        if len(issue['matching_prs']) != 0 or len(issue['matching_commits']) != 0:\n",
    "            if issue['training_labels'][assignee] == 1:\n",
    "                num_positive_labels += 1\n",
    "            total_num_labels += 1\n",
    "print(\"num positive events: \" + str(num_positive_labels))\n",
    "print(\"num total events: \" + str(total_num_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of successful tasks: \n",
      "{'Hixie': 96, 'abarth': 422, 'collinjackson': 7, 'HansMuller': 66, 'devoncarew': 1, 'mpcomplete': 20, 'yjbanov': 14, 'krisgiesing': 4, 'danrubel': 8, 'xster': 6, 'sethladd': 4, 'jason-simmons': 18, 'dragostis': 5, 'jimbeveridge': 1, 'tvolkert': 19, 'chinmaygarde': 2, 'pq': 3, 'aghassemi': 3, 'jakobr-google': 11, 'cbracken': 33, 'gspencergoog': 20, 'dvdwasibi': 1, 'johnmccutchan': 4, 'goderbauer': 13, 'lequem': 1, 'mehmetf': 3, 'mravn-google': 4, 'B3rn475': 2, 'jcollins-g': 11, 'amirh': 3, 'szakarias': 4, 'jonahwilliams': 1, 'aam': 3, 'DanTup': 2, 'mraleph': 3, 'blasten': 1}\n",
      "Number of total tasks: \n",
      "{'abarth': 444, 'eseidelGoogle': 2, 'Hixie': 121, 'collinjackson': 11, 'HansMuller': 75, 'devoncarew': 2, 'vlidholt': 2, 'mpcomplete': 22, 'yjbanov': 20, 'krisgiesing': 5, 'danrubel': 9, 'xster': 17, 'sethladd': 7, 'jason-simmons': 19, 'aghassemi': 7, 'dragostis': 7, 'jimbeveridge': 1, 'tvolkert': 19, 'chinmaygarde': 7, 'pq': 3, 'jakobr-google': 11, 'johnmccutchan': 5, 'cbracken': 39, 'qchong': 1, 'gspencergoog': 22, 'dvdwasibi': 1, 'mit-mit': 2, 'goderbauer': 13, 'lequem': 1, 'LarkAscending': 1, 'mehmetf': 3, 'mravn-google': 5, 'B3rn475': 2, 'jcollins-g': 11, 'amirh': 3, 'szakarias': 4, 'jonahwilliams': 1, 'aam': 3, 'DanTup': 2, 'mraleph': 3, 'a-siva': 1, 'zanderso': 1, 'timsneath': 1, 'blasten': 1}\n",
      "Percentage of tasks completed: \n",
      "{'abarth': 0.9504504504504504, 'eseidelGoogle': 0.0, 'Hixie': 0.7933884297520661, 'collinjackson': 0.6363636363636364, 'HansMuller': 0.88, 'devoncarew': 0.5, 'vlidholt': 0.0, 'mpcomplete': 0.9090909090909091, 'yjbanov': 0.7, 'krisgiesing': 0.8, 'danrubel': 0.8888888888888888, 'xster': 0.35294117647058826, 'sethladd': 0.5714285714285714, 'jason-simmons': 0.9473684210526315, 'aghassemi': 0.42857142857142855, 'dragostis': 0.7142857142857143, 'jimbeveridge': 1.0, 'tvolkert': 1.0, 'chinmaygarde': 0.2857142857142857, 'pq': 1.0, 'jakobr-google': 1.0, 'johnmccutchan': 0.8, 'cbracken': 0.8461538461538461, 'qchong': 0.0, 'gspencergoog': 0.9090909090909091, 'dvdwasibi': 1.0, 'mit-mit': 0.0, 'goderbauer': 1.0, 'lequem': 1.0, 'LarkAscending': 0.0, 'mehmetf': 1.0, 'mravn-google': 0.8, 'B3rn475': 1.0, 'jcollins-g': 1.0, 'amirh': 1.0, 'szakarias': 1.0, 'jonahwilliams': 1.0, 'aam': 1.0, 'DanTup': 1.0, 'mraleph': 1.0, 'a-siva': 0.0, 'zanderso': 0.0, 'timsneath': 0.0, 'blasten': 1.0}\n"
     ]
    }
   ],
   "source": [
    "person_counts = {}\n",
    "person_totals = {}\n",
    "for issue in data:\n",
    "    for assignee in issue['training_labels']:\n",
    "        if len(issue['matching_prs']) != 0 or len(issue['matching_commits']) != 0:\n",
    "            if issue['training_labels'][assignee] == 1:\n",
    "                person_counts[assignee] = person_counts.get(assignee, 0) + 1\n",
    "            person_totals[assignee] = person_totals.get(assignee, 0) + 1\n",
    "person_percents = {}\n",
    "for person in person_totals:\n",
    "    person_percents[person] = person_counts.get(person, 0) / person_totals[person]\n",
    "    \n",
    "print(\"Number of successful tasks: \")\n",
    "print(person_counts)\n",
    "print(\"Number of total tasks: \")\n",
    "print(person_totals)\n",
    "print(\"Percentage of tasks completed: \")\n",
    "print(person_percents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18181818181818182\n"
     ]
    }
   ],
   "source": [
    "zero_count = 0\n",
    "total_count = 0\n",
    "for person in person_percents:\n",
    "    if person_percents[person] == 0.0:\n",
    "        zero_count += 1\n",
    "    total_count += 1\n",
    "print(float(zero_count) / total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: compare characteristics of issues that are successfully completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Think of Features - past history for dev, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'traing_labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-146-0b4498ed76a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m#TODO: figure out how to one-hot-encode labels!!!!!!!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m#TODO: sliding window for user statistics!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mdf_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0missue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'traing_labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'assignee'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mdf_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'traing_labels'"
     ]
    }
   ],
   "source": [
    "df_list = []\n",
    "for issue in data:\n",
    "    issue = preprocess_issue(issue)\n",
    "    for assignee in issue['training_labels']:\n",
    "        df_dict = {}\n",
    "        df_dict['comments'] = issue['comments']\n",
    "        df_dict['assignee'] = assignee\n",
    "        if (not issue['body']):\n",
    "            issue['body'] = \"\"\n",
    "        df_dict['body_length'] = len(issue['body'])\n",
    "        df_dict['code_in_body'] = get_num_code_lines(issue)\n",
    "        df_dict['is_doc_change'] = classify_issue(issue)\n",
    "        #TODO: figure out how to one-hot-encode labels!!!!!!!!\n",
    "        #TODO: sliding window for user statistics!!\n",
    "        df_dict['label'] = issue['traing_labels']['assignee']\n",
    "        df_list.append(df_dict)\n",
    "df = pd.DataFrame(df_list)\n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODOs:\n",
    "# One Hot Encode UserName, Labels, etc.\n",
    "# Sliding windows for previous events for user.\n",
    "# deal with String fields (e.g. assignee)\n",
    "# Use doc classifier as a feature\n",
    "# Use other features\n",
    "# Compare performance to naive model (just take previous % of completion for user...)\n",
    "# Move to 3 class classifier (two binary combined: can predict if they will get a PR up, will that PR be accepted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
