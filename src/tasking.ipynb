{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import operator\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "from classifier import *\n",
    "from heapq import nlargest\n",
    "from issues import get_num_code_lines\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, r2_score\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2153,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/flutter/flutter_issues_labeled.json') as json_data:\n",
    "    issues = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of issues: 7170\n",
      "Number of labeled issues: 2504\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of issues: \" + str(len(issues)))\n",
    "labeled_issues = [issue for issue in issues if len(issue['completed_by']) > 0]\n",
    "print(\"Number of labeled issues: \" + str(len(labeled_issues)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>closed_date</th>\n",
       "      <th>comments</th>\n",
       "      <th>completed_by</th>\n",
       "      <th>created_date</th>\n",
       "      <th>labels</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I try to `flutter start` any of the examp...</td>\n",
       "      <td>2015-11-09 20:13:32</td>\n",
       "      <td>3</td>\n",
       "      <td>[abarth, DanTup]</td>\n",
       "      <td>2015-11-08 20:33:37</td>\n",
       "      <td>[easy fix, tool]</td>\n",
       "      <td>`flutter start` doesn't give good error messag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;a href=\"https://github.com/Hixie\"&gt;&lt;img src=\"h...</td>\n",
       "      <td>2015-11-09 20:18:24</td>\n",
       "      <td>1</td>\n",
       "      <td>[yjbanov]</td>\n",
       "      <td>2015-11-09 20:16:52</td>\n",
       "      <td>[framework, severe: new feature]</td>\n",
       "      <td>Swipe to change between Tabs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body         closed_date  \\\n",
       "1  When I try to `flutter start` any of the examp... 2015-11-09 20:13:32   \n",
       "6  <a href=\"https://github.com/Hixie\"><img src=\"h... 2015-11-09 20:18:24   \n",
       "\n",
       "   comments      completed_by        created_date  \\\n",
       "1         3  [abarth, DanTup] 2015-11-08 20:33:37   \n",
       "6         1         [yjbanov] 2015-11-09 20:16:52   \n",
       "\n",
       "                             labels  \\\n",
       "1                  [easy fix, tool]   \n",
       "6  [framework, severe: new feature]   \n",
       "\n",
       "                                               title  \n",
       "1  `flutter start` doesn't give good error messag...  \n",
       "6                       Swipe to change between Tabs  "
      ]
     },
     "execution_count": 2155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a data frame from the list of issues\n",
    "df_list = []\n",
    "for issue in labeled_issues[25:]:\n",
    "        df_dict = {}\n",
    "        df_dict['comments'] = issue['comments']\n",
    "        if (not issue['body']):\n",
    "            issue['body'] = \"\"\n",
    "        df_dict['title'] = issue['title']\n",
    "        df_dict['body'] = issue['body']\n",
    "        df_dict['closed_date'] = pd.to_datetime(issue['closed_at'])\n",
    "        df_dict['created_date'] = pd.to_datetime(issue['created_at'])\n",
    "        df_dict['completed_by'] = issue['completed_by']\n",
    "        df_dict['labels'] = [label['name'] for label in issue['labels']]\n",
    "        df_list.append(df_dict)\n",
    "df = pd.DataFrame(df_list).sort_values('closed_date')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 197, 1: 2268, 3: 14}\n",
      "Number of total issues: 2479\n",
      "Number of issues with single solver: 2268\n"
     ]
    }
   ],
   "source": [
    "# count number of issues with multiple completers\n",
    "counts = {}\n",
    "for index, row in df.iterrows():\n",
    "    count = len(row['completed_by'])\n",
    "    counts[count] = counts.get(count, 0) + 1\n",
    "print(counts)\n",
    "#TODO: confirm that filtering \"noise\" is best strategy here\n",
    "print(\"Number of total issues: \" + str(len(df)))\n",
    "df = df[df.apply(lambda x: len(x['completed_by']) == 1, axis=1)].reset_index(drop=True)\n",
    "df['completed_by'] = df['completed_by'].apply(lambda  x : x[0])\n",
    "print(\"Number of issues with single solver: \" + str(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>closed_date</th>\n",
       "      <th>comments</th>\n",
       "      <th>completed_by</th>\n",
       "      <th>created_date</th>\n",
       "      <th>title</th>\n",
       "      <th>a: accessibility</th>\n",
       "      <th>a: animation</th>\n",
       "      <th>a: china</th>\n",
       "      <th>a: fidelity</th>\n",
       "      <th>...</th>\n",
       "      <th>team: gallery</th>\n",
       "      <th>tool</th>\n",
       "      <th>waiting for PR to land (fixed)</th>\n",
       "      <th>waiting for customer response</th>\n",
       "      <th>⌘‬ platform-mac</th>\n",
       "      <th>⌺‬ platform-ios</th>\n",
       "      <th>▣ platform-android</th>\n",
       "      <th>○ platform-fuchsia</th>\n",
       "      <th>⚠ TODAY</th>\n",
       "      <th>❖ platform-windows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;a href=\"https://github.com/Hixie\"&gt;&lt;img src=\"h...</td>\n",
       "      <td>2015-11-09 20:18:24</td>\n",
       "      <td>1</td>\n",
       "      <td>yjbanov</td>\n",
       "      <td>2015-11-09 20:16:52</td>\n",
       "      <td>Swipe to change between Tabs</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flutter start --debug\\nsevere: To copy files t...</td>\n",
       "      <td>2015-11-09 21:43:40</td>\n",
       "      <td>1</td>\n",
       "      <td>abarth</td>\n",
       "      <td>2015-11-09 20:50:45</td>\n",
       "      <td>Exception running source build of engine on Mac</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body         closed_date  \\\n",
       "0  <a href=\"https://github.com/Hixie\"><img src=\"h... 2015-11-09 20:18:24   \n",
       "1  flutter start --debug\\nsevere: To copy files t... 2015-11-09 21:43:40   \n",
       "\n",
       "   comments completed_by        created_date  \\\n",
       "0         1      yjbanov 2015-11-09 20:16:52   \n",
       "1         1       abarth 2015-11-09 20:50:45   \n",
       "\n",
       "                                             title  a: accessibility  \\\n",
       "0                     Swipe to change between Tabs                 0   \n",
       "1  Exception running source build of engine on Mac                 0   \n",
       "\n",
       "   a: animation  a: china  a: fidelity         ...          team: gallery  \\\n",
       "0             0         0            0         ...                      0   \n",
       "1             0         0            0         ...                      0   \n",
       "\n",
       "   tool  waiting for PR to land (fixed)  waiting for customer response  \\\n",
       "0     0                               0                              0   \n",
       "1     1                               0                              0   \n",
       "\n",
       "   ⌘‬ platform-mac  ⌺‬ platform-ios  ▣ platform-android  ○ platform-fuchsia  \\\n",
       "0                0                0                   0                   0   \n",
       "1                0                0                   0                   0   \n",
       "\n",
       "   ⚠ TODAY  ❖ platform-windows  \n",
       "0        0                   0  \n",
       "1        0                   0  \n",
       "\n",
       "[2 rows x 83 columns]"
      ]
     },
     "execution_count": 2157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encode the label column\n",
    "mlb = MultiLabelBinarizer()\n",
    "df = df.join(pd.DataFrame(mlb.fit_transform(df.pop('labels')),\n",
    "                          columns=mlb.classes_,\n",
    "                          index=df.index))\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    # remove punctuation and non-alpha numeric characters\n",
    "    split1 = ' '.join([word for word in re.split('\\W+', text) if word.isalpha()])\n",
    "    # split camel case words apart (necessary for embedded code) and apply stemmer to all words\n",
    "    split2 = ' '.join([stemmer.stem(word) for word in re.sub('(?!^)([A-Z][a-z]+)', r' \\1', split1).split()])\n",
    "    return split2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2159,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2159-1c7ae6a04171>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# use tf-idf w/ stemming, stop-word removal, and non-alphabetic word removal to generate features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'body'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'body'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mvectorizer_body\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mENGLISH_STOP_WORDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvectorizer_body\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'body'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvector_body\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer_body\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'body'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3190\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3191\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3192\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3194\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2158-32574dd7a282>\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msplit1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\W+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misalpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# split camel case words apart (necessary for embedded code) and apply stemmer to all words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0msplit2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstemmer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'(?!^)([A-Z][a-z]+)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mr' \\1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msplit2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2158-32574dd7a282>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msplit1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\W+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misalpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# split camel case words apart (necessary for embedded code) and apply stemmer to all words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0msplit2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstemmer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'(?!^)([A-Z][a-z]+)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mr' \\1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msplit2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/nltk/stem/porter.py\u001b[0m in \u001b[0;36mstem\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0mstem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLTK_EXTENSIONS\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    657\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# use tf-idf w/ stemming, stop-word removal, and non-alphabetic word removal to generate features\n",
    "df['body'] = df['body'].apply(preprocess)\n",
    "vectorizer_body = TfidfVectorizer(stop_words=ENGLISH_STOP_WORDS)\n",
    "vectorizer_body.fit(df['body'])\n",
    "vector_body = vectorizer_body.transform(df['body'])\n",
    "# summarize encoded vector\n",
    "print(vector_body.shape)\n",
    "df['title'] = df['title'].apply(preprocess)\n",
    "vectorizer_title = TfidfVectorizer(stop_words=ENGLISH_STOP_WORDS)\n",
    "vectorizer_title.fit(df['title'])\n",
    "vector_title = vectorizer_title.transform(df['title'])\n",
    "# summarize encoded vector\n",
    "print(vector_title.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_df = pd.DataFrame(vector_title.todense())\n",
    "body_df = pd.DataFrame(vector_body.todense())\n",
    "df = pd.concat([df, title_df, body_df], axis=1)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of devs who solve an issue in last three months (from end of train set)\n",
    "active_devs = set()\n",
    "dev_counts = {}\n",
    "filter_date = df.iloc[2000]['closed_date'] - pd.to_timedelta(90, unit='d')\n",
    "for _, row in df.iterrows():\n",
    "    if (row['closed_date'] > filter_date):\n",
    "        dev_counts[row['completed_by']] = dev_counts.get(row['completed_by'], 0) + 1\n",
    "print(dev_counts)\n",
    "for dev in dev_counts:\n",
    "    if dev_counts[dev] >= 3:\n",
    "        active_devs.add(dev)\n",
    "print(active_devs)\n",
    "# remove all issues not solved by an active dev\n",
    "df = df[df['completed_by'].isin(active_devs)].reset_index(drop=True)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[:1100]\n",
    "test_df = df[1100:]\n",
    "X_train = train_df.drop(['body', 'closed_date', 'completed_by', 'created_date', 'title', 'comments'], axis=1)\n",
    "y_train = train_df['completed_by']\n",
    "X_test = test_df.drop(['body', 'closed_date', 'completed_by', 'created_date', 'title', 'comments'], axis=1)\n",
    "y_test = test_df['completed_by']\n",
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_correct_top_k(pred_prob, k, actual, labels):\n",
    "    indices = [i for i in range(len(pred_prob))]\n",
    "    top_indices = nlargest(k, indices, key=lambda i: pred_prob[i])\n",
    "    top_choices = set([labels[i] for i in top_indices])\n",
    "    return actual in top_choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = MLPClassifier(hidden_layer_sizes=(25,25))\n",
    "classifier.fit(X_train,y_train)\n",
    "classes = classifier.classes_\n",
    "print(\"Top 1 Accuracy: \" + str(classifier.score(X_test, y_test)))\n",
    "pred_probs = classifier.predict_proba(X_test)\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 2, y_test[1100 + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 2 Accuracy: \" + str((correct/len(y_test))))\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 3, y_test[1100 + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 3 Accuracy: \" + str((correct/len(y_test))))\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 4, y_test[1100 + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 4 Accuracy: \" + str((correct/len(y_test))))\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 5, y_test[1100 + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 5 Accuracy: \" + str((correct/len(y_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train,y_train)\n",
    "classes = classifier.classes_\n",
    "print(\"Top 1 Accuracy: \" + str(classifier.score(X_test, y_test)))\n",
    "pred_probs = classifier.predict_proba(X_test)\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 2, y_test[1100 + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 2 Accuracy: \" + str((correct/len(y_test))))\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 3, y_test[1100 + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 3 Accuracy: \" + str((correct/len(y_test))))\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 4, y_test[1100 + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 4 Accuracy: \" + str((correct/len(y_test))))\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 5, y_test[1100 + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 5 Accuracy: \" + str((correct/len(y_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = BernoulliNB()\n",
    "classifier.fit(X_train,y_train)\n",
    "classes = classifier.classes_\n",
    "print(\"Top 1 Accuracy: \" + str(classifier.score(X_test, y_test)))\n",
    "pred_probs = classifier.predict_proba(X_test)\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 2, y_test[1100 + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 2 Accuracy: \" + str((correct/len(y_test))))\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 3, y_test[1100 + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 3 Accuracy: \" + str((correct/len(y_test))))\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 4, y_test[1100 + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 4 Accuracy: \" + str((correct/len(y_test))))\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 5, y_test[1100 + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 5 Accuracy: \" + str((correct/len(y_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "classifier.fit(X_train, y_train)\n",
    "classes = classifier.classes_\n",
    "print(\"Top 1 Accuracy: \" + str(classifier.score(X_test, y_test)))\n",
    "pred_probs = classifier.predict_proba(X_test)\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 2, y_test[1100 + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 2 Accuracy: \" + str((correct/len(y_test))))\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 3, y_test[1100 + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 3 Accuracy: \" + str((correct/len(y_test))))\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 4, y_test[1100 + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 4 Accuracy: \" + str((correct/len(y_test))))\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 5, y_test[1100 + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 5 Accuracy: \" + str((correct/len(y_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=1000)\n",
    "classifier.fit(X_train, y_train)\n",
    "classes = classifier.classes_\n",
    "print(\"Top 1 Accuracy: \" + str(classifier.score(X_test, y_test)))\n",
    "pred_probs = classifier.predict_proba(X_test)\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 2, y_test[1100 + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 2 Accuracy: \" + str((correct/len(y_test))))\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 3, y_test[1100 + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 3 Accuracy: \" + str((correct/len(y_test))))\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 4, y_test[1100 + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 4 Accuracy: \" + str((correct/len(y_test))))\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 5, y_test[1100 + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 5 Accuracy: \" + str((correct/len(y_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: try SVC (might need to do something else)\n",
    "classifier = SVC(probability=True)\n",
    "classifier.fit(X_train, y_train)\n",
    "classes = classifier.classes_\n",
    "print(\"Top 1 Accuracy: \" + str(classifier.score(X_test, y_test)))\n",
    "pred_probs = classifier.predict_proba(X_test)\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 2, y_test[1100 + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 2 Accuracy: \" + str((correct/len(y_test))))\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 3, y_test[1100 + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 3 Accuracy: \" + str((correct/len(y_test))))\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 4, y_test[1100 + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 4 Accuracy: \" + str((correct/len(y_test))))\n",
    "correct = 0\n",
    "for idx, pred in enumerate(pred_probs):\n",
    "    if is_correct_top_k(pred, 5, y_test[1100 + idx], classes):\n",
    "        correct += 1\n",
    "print (\"Top 5 Accuracy: \" + str((correct/len(y_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = MLPClassifier(hidden_layer_sizes=(25,25))\n",
    "classifier.fit(X_train,y_train)\n",
    "preds = classifier.predict(X_test)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = test_df['completed_by']\n",
    "pd.value_counts(actual).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(df['completed_by']).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(preds).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_counts = pd.value_counts(df['completed_by'])\n",
    "# list of devs sorted in order of highest contribution\n",
    "sorted_dev_list = overall_counts.index.values\n",
    "pred_counts = pd.value_counts(preds)\n",
    "actual_counts = pd.value_counts(actual)\n",
    "\n",
    "percent_diff = {}\n",
    "vals = []\n",
    "counts = []\n",
    "missing = set()\n",
    "for dev in sorted_dev_list:\n",
    "    if dev in pred_counts:\n",
    "        val = 100 * (pred_counts[dev] - actual_counts[dev]) / (actual_counts[dev])\n",
    "        percent_diff[dev] = val\n",
    "        counts.append(overall_counts[dev])\n",
    "        vals.append(val)\n",
    "    else:\n",
    "        missing.add(dev)\n",
    "print(\"devs not included in predictions: \")\n",
    "print(list(missing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(percent_diff.keys(), percent_diff.values())\n",
    "plt.title(\"Percent Difference Prediction Rate vs. Actual Rate\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the outlier\n",
    "del vals[2]\n",
    "del counts[2]\n",
    "# create best fit line\n",
    "z = np.polyfit(x=counts, y=vals, deg=1)\n",
    "p = np.poly1d(z)\n",
    "trend_line = p(counts)\n",
    "# test best fit\n",
    "yhat = trend_line    \n",
    "ybar = np.sum(vals)/len(vals)\n",
    "ssreg = np.sum((yhat-ybar)**2) \n",
    "sstot = np.sum((vals - ybar)**2)\n",
    "print(\"R^2: \" + str(ssreg / sstot))\n",
    "# create plots\n",
    "plt.scatter(counts, vals)\n",
    "plt.title(\"Percent Difference Between Prediction Rate and Actual Rate vs. Issue Count\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel(\"Number of Issues Solved\")\n",
    "plt.ylabel(\"% diff. pred rate and actual rate\")\n",
    "plt.plot(counts, trend_line)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: look at assigning open issues and seeing what overspecialization problem would look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.tail(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
