{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1161,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1161-ff2f345e6fc8>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1161-ff2f345e6fc8>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    from sklearn.ensemble importRandomForestClassifier\u001b[0m\n\u001b[0m                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "from classifier import *\n",
    "from issues import get_num_code_lines\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.ensemble import importRandomForestClassifier\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/flutter/flutter_issues_labeled.json') as json_data:\n",
    "    issues = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of issues: \" + str(len(issues)))\n",
    "labeled_issues = [issue for issue in issues if len(issue['completed_by']) > 0]\n",
    "print(\"Number of labeled issues: \" + str(len(labeled_issues)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a data frame from the list of issues\n",
    "df_list = []\n",
    "for issue in labeled_issues[25:]:\n",
    "        df_dict = {}\n",
    "        df_dict['comments'] = issue['comments']\n",
    "        if (not issue['body']):\n",
    "            issue['body'] = \"\"\n",
    "        df_dict['title'] = issue['title']\n",
    "        df_dict['body'] = issue['body']\n",
    "        df_dict['closed_date'] = pd.to_datetime(issue['closed_at'])\n",
    "        df_dict['created_date'] = pd.to_datetime(issue['created_at'])\n",
    "        df_dict['completed_by'] = issue['completed_by']\n",
    "        #TODO: figure out how to one-hot-encode labels!!!!!!!!\n",
    "        df_dict['labels'] = [label['name'] for label in issue['labels']]\n",
    "        df_list.append(df_dict)\n",
    "df = pd.DataFrame(df_list).sort_values('closed_date')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of issues with multiple completers\n",
    "counts = {}\n",
    "for index, row in df.iterrows():\n",
    "    count = len(row['completed_by'])\n",
    "    counts[count] = counts.get(count, 0) + 1\n",
    "print(counts)\n",
    "#TODO: confirm that filtering \"noise\" is best strategy here\n",
    "print(\"Number of total issues: \" + str(len(df)))\n",
    "df = df[df.apply(lambda x: len(x['completed_by']) == 1, axis=1)].reset_index(drop=True)\n",
    "df['completed_by'] = df['completed_by'].apply(lambda  x : x[0])\n",
    "print(\"Number of issues with single solver: \" + str(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode the label column\n",
    "mlb = MultiLabelBinarizer()\n",
    "df = df.join(pd.DataFrame(mlb.fit_transform(df.pop('labels')),\n",
    "                          columns=mlb.classes_,\n",
    "                          index=df.index))\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    # remove punctuation and non-alpha numeric characters\n",
    "    split1 = ' '.join([word for word in re.split('\\W+', text) if word.isalpha()])\n",
    "    # split camel case words apart (necessary for embedded code) and apply stemmer to all words\n",
    "    split2 = ' '.join([stemmer.stem(word) for word in re.sub('(?!^)([A-Z][a-z]+)', r' \\1', split1).split()])\n",
    "    return split2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use tf-idf w/ stemming, stop-word removal, and non-alphabetic word removal to generate features\n",
    "df['body'] = df['body'].apply(preprocess)\n",
    "vectorizer_body = TfidfVectorizer(stop_words=ENGLISH_STOP_WORDS)\n",
    "vectorizer_body.fit(df['body'])\n",
    "vector_body = vectorizer_body.transform(df['body'])\n",
    "# summarize encoded vector\n",
    "print(vector_body.shape)\n",
    "df['title'] = df['title'].apply(preprocess)\n",
    "vectorizer_title = TfidfVectorizer(stop_words=ENGLISH_STOP_WORDS)\n",
    "vectorizer_title.fit(df['title'])\n",
    "vector_title = vectorizer_title.transform(df['title'])\n",
    "# summarize encoded vector\n",
    "print(vector_title.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_df = pd.DataFrame(vector_title.todense())\n",
    "body_df = pd.DataFrame(vector_body.todense())\n",
    "df = pd.concat([df, title_df, body_df], axis=1)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of devs who solve an issue in last three months (from end of train set)\n",
    "active_devs = set()\n",
    "dev_counts = {}\n",
    "filter_date = df.iloc[2000]['closed_date'] - pd.to_timedelta(90, unit='d')\n",
    "for _, row in df.iterrows():\n",
    "    if (row['closed_date'] > filter_date):\n",
    "        dev_counts[row['completed_by']] = dev_counts.get(row['completed_by'], 0) + 1\n",
    "print(dev_counts)\n",
    "for dev in dev_counts:\n",
    "    if dev_counts[dev] >= 4:\n",
    "        active_devs.add(dev)\n",
    "print(active_devs)\n",
    "# remove all issues not solved by an active dev\n",
    "df = df[df['completed_by'].isin(active_devs)].reset_index(drop=True)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[:1200]\n",
    "test_df = df[1200:]\n",
    "X_train = train_df.drop(['body', 'closed_date', 'completed_by', 'created_date', 'title'], axis=1)\n",
    "y_train = train_df['completed_by']\n",
    "X_test = test_df.drop(['body', 'closed_date', 'completed_by', 'created_date', 'title'], axis=1)\n",
    "y_test = test_df['completed_by']\n",
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(X_train,y_train)\n",
    "preds = classifier.predict(X_test)\n",
    "correct = 0\n",
    "for idx, pred in enumerate(preds):\n",
    "    if pred == y_test[1200 + idx]:\n",
    "        correct += 1\n",
    "print (correct/len(y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
